{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"PySGtSNEpi","text":"<p>PySGtSNEpi is a Python module (wrapper) implementing the Swift Neighbor Embedding of Sparse Stochastic Graphs (SG-t-SNE-\u03a0) algorithm.</p>"},{"location":"index.html#features","title":"\ud83d\ude80 Features","text":"<ul> <li> <p>SGtSNEpi   Embed sparse stochastic graphs. [TBD]</p> </li> <li> <p>Lambda Equalization   Equalize the local entropy of columns in a matrix.</p> </li> </ul>"},{"location":"index.html#contributing","title":"\ud83d\udee0 Contributing","text":"<p>We welcome contributions to improve mheatmap! Please follow these steps:</p> <ol> <li>Fork the repository</li> <li>Create a new branch (<code>feature-branch</code>)</li> <li>Commit your changes</li> <li>Open a pull request</li> </ol>"},{"location":"index.html#links","title":"\ud83d\udd17 Links","text":"<ul> <li>SGtSNEpi.jl</li> <li>sgtsnepi</li> </ul>"},{"location":"index.html#citation","title":"\ud83d\udcdd Citation","text":"<p>If you use our package, please cite:</p> <pre><code>@inproceedings{pitsianis2019hpec,\n  title = {Spaceland Embedding of Sparse Stochastic Graphs},\n  booktitle = {{{IEEE High Performance Extreme Computing Conference}}},\n  author = {Pitsianis, Nikos and Iliopoulos, Alexandros-Stavros and Floros, Dimitris and Sun, Xiaobai},\n  date = {2019},\n  doi = {10.1109/HPEC.2019.8916505}\n}\n\n@article{pitsianis2019joss,\n  title = {{{SG-t-SNE-\u03a0}}: Swift Neighbor Embedding of Sparse Stochastic Graphs},\n  author = {Pitsianis, Nikos and Floros, Dimitris and Iliopoulos, Alexandros-Stavros and Sun, Xiaobai},\n  date = {2019},\n  journaltitle = {Journal of Open Source Software},\n  volume = {4},\n  number = {39},\n  pages = {1577},\n  issn = {2475-9066},\n  doi = {10.21105/joss.01577},\n  url = {http://dx.doi.org/10.21105/joss.01577}\n}\n</code></pre>"},{"location":"index.html#license","title":"\ud83d\udcdd License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for details.</p>"},{"location":"install.html","title":"\ud83d\udce6 Installation","text":""},{"location":"install.html#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install pysgtsnepi\n</code></pre>"},{"location":"install.html#install-from-source","title":"Install from source","text":"<pre><code>git clone https://github.com/qqgjyx/pysgtsnepi.git\ncd pysgtsnepi\npip install .\n</code></pre>"},{"location":"api/index.html","title":"API Reference","text":""},{"location":"api/index.html#utils","title":"<code>utils</code>","text":"Module Description <code>sgtsne_lambda_equalization</code> Equalize the local entropy of columns in a matrix"},{"location":"api/lambda-eq.html","title":"<code>sgtsne_lambda_equalization</code>","text":""},{"location":"api/lambda-eq.html#src.pysgtsnepi.utils.sgtsne_lambda_equalization.sgtsne_lambda_equalization","title":"<code>sgtsne_lambda_equalization(D, lambda_, max_iter=50, tol_binary=1e-05, algorithm='custom_bisection')</code>","text":"<p>Binary search for the scales of column-wise conditional probabilities.</p> <p>Binary search for the scales of column-wise conditional probabilities from exp(-D) to exp(-D/\u03c3\u00b2)/z equalized by \u03bb.</p> <p>Parameters:</p> Name Type Description Default <code>D</code> <code>csc_matrix</code> <p>N x N sparse matrix of \"distance square\" (column-wise conditional, local distances)</p> required <code>lambda_</code> <code>float</code> <p>The equalization parameter</p> required <code>max_iter</code> <code>int</code> <p>Maximum number of iterations for binary search, by default 50</p> <code>50</code> <code>tol_binary</code> <code>float</code> <p>Tolerance for binary search convergence, by default 1e-5</p> <code>1e-05</code> <code>algorithm</code> <code>str</code> <p>The root finding algorithm to use, by default \"custom_bisection\"</p> <code>'custom_bisection'</code> <p>Returns:</p> Type Description <code>csc_matrix</code> <p>The column-wise conditional probability matrix</p> Notes <p>.. versionadded:: 0.1.0</p> Author <p>Xiaobai Sun (MATLAB prototype on May 12, 2019) Dimitris Floros (translation to Julia) Juntang Wang (translation to Python on Nov 16, 2024)</p> Source code in <code>src/pysgtsnepi/utils/sgtsne_lambda_equalization.py</code> <pre><code>def sgtsne_lambda_equalization(\n    D: csc_matrix,\n    lambda_: float,\n    max_iter: int = 50,\n    tol_binary: float = 1e-5,\n    algorithm: Literal[\n        \"custom_bisection\",\n        \"bisection\",\n        \"brentq\",\n        \"brenth\",\n        \"bisect\",\n        \"ridder\",\n        \"newton\",\n        \"secant\",\n        \"halley\",\n    ] = \"custom_bisection\",\n) -&gt; csc_matrix:\n    \"\"\"Binary search for the scales of column-wise conditional probabilities.\n\n    Binary search for the scales of column-wise conditional probabilities\n    from exp(-D) to exp(-D/\u03c3\u00b2)/z equalized by \u03bb.\n\n    Parameters\n    ----------\n    D : scipy.sparse.csc_matrix\n        N x N sparse matrix of \"distance square\"\n        (column-wise conditional, local distances)\n    lambda_ : float\n        The equalization parameter\n    max_iter : int, optional\n        Maximum number of iterations for binary search, by default 50\n    tol_binary : float, optional\n        Tolerance for binary search convergence, by default 1e-5\n    algorithm : str, optional\n        The root finding algorithm to use, by default \"custom_bisection\"\n\n    Returns\n    -------\n    scipy.sparse.csc_matrix\n        The column-wise conditional probability matrix\n\n    Notes\n    -----\n    .. versionadded:: 0.1.0\n\n    Author\n    ------\n    Xiaobai Sun (MATLAB prototype on May 12, 2019)\n    Dimitris Floros (translation to Julia)\n    Juntang Wang (translation to Python on Nov 16, 2024)\n    \"\"\"\n\n    #############################################################################\n    #                          private helper functions                         #\n    #############################################################################\n\n    def colsum(D, j, sigma=1.0):\n        \"\"\"Helper function to compute column sum\"\"\"\n\n        # minimum possible value (python float precision)\n        D_min = np.finfo(float).tiny\n\n        vals = D.data[D.indptr[j] : D.indptr[j + 1]]\n        sum_j = np.sum(np.exp(-vals * sigma))\n        return max(sum_j, D_min)\n\n    def colupdate(D, j, sigma):\n        \"\"\"Helper function to update column values\"\"\"\n        start, end = D.indptr[j], D.indptr[j + 1]\n        D.data[start:end] = np.exp(-D.data[start:end] * sigma)\n\n    #############################################################################\n    #                 parameter setting &amp; memory pre-allocations                #\n    #############################################################################\n\n    n = D.shape[0]\n    cond_P = D.copy()\n\n    i_diff = np.zeros(n)\n    i_count = np.zeros(n)\n    i_tval = np.zeros(n)\n    sigma_sq = np.ones(n)\n\n    #############################################################################\n    #                       pre-calculate average entropy                       #\n    #############################################################################\n\n    for j in range(n):  # loop over all columns of D\n        sum_j = colsum(D, j)\n        i_tval[j] = sum_j - lambda_  # difference from \u03bb\n\n    #############################################################################\n    #                        search for \u03c3\u00b2                                      #\n    #############################################################################\n\n    if algorithm == \"custom_bisection\":\n        for j in range(n):  # loop over all columns of D\n            fval = i_tval[j]\n            lb, ub = -1000.0, np.inf  # lower and upper bounds\n\n            iter_count = 0\n\n            while abs(fval) &gt; tol_binary and iter_count &lt; max_iter:\n                iter_count += 1\n\n                if fval &gt; 0:  # update lower bound\n                    lb = sigma_sq[j]\n                    sigma_sq[j] = 2 * lb if np.isinf(ub) else 0.5 * (lb + ub)\n                else:  # update upper bound\n                    ub = sigma_sq[j]\n                    sigma_sq[j] = 0.5 * ub if np.isinf(lb) else 0.5 * (lb + ub)\n\n                # Re-calculate local entropy\n                sum_j = colsum(D, j, sigma_sq[j])\n                fval = sum_j - lambda_\n\n            # Post-recording\n            i_diff[j] = fval\n            i_count[j] = iter_count\n            colupdate(cond_P, j, sigma_sq[j])\n\n    else:  # Use any scipy.optimize root finding method\n        for j in range(n):\n            # Define the objective function\n            def objective(x):\n                return colsum(D, j, x) - lambda_\n\n            try:\n                # For methods that require brackets\n                if algorithm in [\"brentq\", \"brenth\", \"bisect\", \"ridder\"]:\n                    result = root_scalar(\n                        objective,\n                        method=algorithm,\n                        bracket=[-1000.0, np.inf],\n                        xtol=tol_binary,\n                        maxiter=max_iter,\n                        full_output=True,\n                    )\n                # For methods that require initial guess\n                elif algorithm in [\"newton\", \"secant\", \"halley\"]:\n                    result = root_scalar(\n                        objective,\n                        method=algorithm,\n                        x0=1.0,\n                        xtol=tol_binary,\n                        maxiter=max_iter,\n                        full_output=True,\n                    )\n                else:\n                    raise ValueError(f\"Unsupported root finding method: {algorithm}\")\n\n                sigma_sq[j] = result.root\n                i_diff[j] = objective(sigma_sq[j])\n                i_count[j] = result.iterations\n                colupdate(cond_P, j, sigma_sq[j])\n\n            except (ValueError, RuntimeError) as e:\n                # If root finding fails, use the initial value\n                msg = (\n                    f\"Failed for column {j} with {algorithm} method: {str(e)}\"\n                )\n                warnings.warn(msg)\n                sigma_sq[j] = 1.0\n                i_diff[j] = objective(sigma_sq[j])\n                i_count[j] = 0\n                colupdate(cond_P, j, sigma_sq[j])\n\n    #############################################################################\n    #                      display post-information to user                     #\n    #############################################################################\n\n    avg_iter = np.ceil(np.sum(i_count) / n)\n    nc_idx = np.sum(np.abs(i_diff) &gt; tol_binary)\n\n    if nc_idx == 0:\n        print(f\"\u2705 All {n} elements converged numerically, avg(#iter) = {avg_iter}\")\n    else:\n        warnings.warn(f\"There are {nc_idx} non-convergent elements out of {n}\")\n\n    n_neg = np.sum(sigma_sq &lt; 0)\n    if n_neg &gt; 0:\n        warnings.warn(\n            f\"There are {n_neg} nodes with negative \u03b3\u1d62; consider decreasing \u03bb\"\n        )\n\n    return cond_P\n</code></pre>"},{"location":"examples/lambda_eq.html","title":"Python version","text":"<pre><code>import numpy as np\nfrom scipy.sparse import csc_matrix\nimport warnings\n\nfrom typing import Literal\n\nfrom scipy.optimize import root_scalar\n\nfrom sgtsnepi import sgtsne_lambda_equalization\n</code></pre> <pre><code>import scipy\n\nD = scipy.io.loadmat(\".cluster_only/kNN/SalinasA_A_11.mat\")[\"D\"]\n\nP = sgtsne_lambda_equalization(D, 10)\n</code></pre> <pre><code>\u2705 All 7138 elements converged numerically, avg(#iter) = 16.0\n</code></pre> <pre><code>scipy.io.savemat(\"temp_py.mat\", {\"P\": P})\n</code></pre> <pre><code># spy plot the P\nimport matplotlib.pyplot as plt\nplt.spy(P, markersize=1)\nplt.show()\n</code></pre> <pre><code># Print basic properties of P\nprint(f\"Shape: {P.shape}\")\nprint(f\"Non-zero elements (nnz): {P.nnz}\")\nsparsity_py = 1 - (P.nnz / (P.shape[0] * P.shape[1]))\nprint(f\"Sparsity: {sparsity_py:.6f}\")\nmax_val = np.max(P.data)\nmin_val = np.min(P.data)\nprint(f\"Max value: {max_val:.6f}\")\nprint(f\"Min value: {min_val:.6f}\")\nmean_val = np.mean(P.data)\nprint(f\"Mean value: {mean_val:.6f}\")\nmedian_val = np.median(P.data)\nprint(f\"Median value: {median_val:.6f}\")\n# distribution\nplt.hist(P.data, bins=50, edgecolor='black')\nplt.title(\"Distribution of non-zero values in P\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Frequency\")\nplt.show()\n</code></pre> <pre><code>Shape: (7138, 7138)\nNon-zero elements (nnz): 78518\nSparsity: 0.998459\nMax value: 1.000000\nMin value: 0.823821\nMean value: 0.909091\nMedian value: 0.903382\n</code></pre>"},{"location":"examples/lambda_eq.html#julia-version","title":"Julia version","text":"<pre><code># Calculate sparsity\nsparsity_jl = 1 - (nnz(P) / (size(P, 1) * size(P, 2)))\nprintln(\"Sparsity: \", round(sparsity_jl, digits=6))\n\n# Extract non-zero values\nnz_values = nonzeros(P)\n\n# Calculate max and min\nmax_val = maximum(nz_values)\nmin_val = minimum(nz_values)\nprintln(\"Max value: \", round(max_val, digits=6))\nprintln(\"Min value: \", round(min_val, digits=6))\n\n# Calculate mean and median of non-zero values\nmean_val = mean(nz_values)\nmedian_val = median(nz_values)\n\n# Print results\nprintln(\"Mean value: \", round(mean_val, digits=6))\nprintln(\"Median value: \", round(median_val, digits=6))\n\n# Plot histogram\nhistogram(nz_values, bins=50, edgecolor=:black, title=\"Distribution of non-zero values in P\", xlabel=\"Value\", ylabel=\"Frequency\")\n</code></pre> <pre><code>Sparsity: 0.998459\nMax value: 1.0\nMin value: 0.823821\nMean value: 0.909091\nMedian value: 0.903382\n</code></pre>"},{"location":"examples/lambda_eq.html#_1","title":"sgtsne_lambda_equalization","text":""},{"location":"examples/lambda_eq.html#_2","title":"sgtsne_lambda_equalization","text":""},{"location":"user-guide/index.html","title":"User Guide","text":"<p>Not implemented: [TBD] </p>"}]}